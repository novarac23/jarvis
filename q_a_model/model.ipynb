{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is base model we have here good enough? - we ended up using albert\n",
    "# explore improvements\n",
    "  # Maybe different flavor of bert? [X]\n",
    "  # Maybe try a few different models and measure F1 scores?\n",
    "  # better information retrieval? \n",
    "  # Maybe try and fine tune on a different dataset?\n",
    "  # chunk in a way that we tend to get full sentances? Right now a chunk can stop at a random spot in the sentance\n",
    "    \n",
    "  # a few ideas that can help with first three improvemetns are here https://towardsdatascience.com/which-flavor-of-bert-should-you-use-for-your-qa-task-6d6a0897fb24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# script to fine tune the model (it's fine tuned on squad 2.0)\n",
    "\n",
    "# !python run_squad.py  \\\n",
    "#     --model_type bert   \\\n",
    "#     --model_name_or_path bert-base-uncased  \\\n",
    "#     --output_dir models/bert/ \\\n",
    "#     --data_dir dataset/   \\\n",
    "#     --overwrite_output_dir \\\n",
    "#     --overwrite_cache \\\n",
    "#     --do_train  \\\n",
    "#     --train_file train-v2.0.json   \\\n",
    "#     --version_2_with_negative \\\n",
    "#     --do_lower_case  \\\n",
    "#     --do_eval   \\\n",
    "#     --predict_file dev-v2.0.json   \\\n",
    "#     --per_gpu_train_batch_size 2   \\\n",
    "#     --learning_rate 3e-5   \\\n",
    "#     --num_train_epochs 2.0   \\\n",
    "#     --max_seq_length 384   \\\n",
    "#     --doc_stride 128   \\\n",
    "#     --threads 10   \\\n",
    "#     --save_steps 5000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import wikipedia\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from collections import OrderedDict\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, TFAutoModelForQuestionAnswering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForQuestionAnswering.\n",
      "\n",
      "All the weights of TFBertForQuestionAnswering were initialized from the TF 2.0 model.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use TFBertForQuestionAnswering for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"models/bert\")\n",
    "model = TFAutoModelForQuestionAnswering.from_pretrained(\"models/bert\", from_pt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"When did world war 2 start?\"\n",
    "\n",
    "q_search = wikipedia.search(question)\n",
    "page = wikipedia.page(q_search[0])\n",
    "context = page.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (7 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(question, context, add_special_tokens=True, return_tensors=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': <tf.Tensor: shape=(1, 30088), dtype=int32, numpy=array([[ 101, 2043, 2106, ..., 1997, 7649,  102]], dtype=int32)>, 'token_type_ids': <tf.Tensor: shape=(1, 30088), dtype=int32, numpy=array([[0, 0, 0, ..., 1, 1, 1]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(1, 30088), dtype=int32, numpy=array([[1, 1, 1, ..., 1, 1, 1]], dtype=int32)>}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# answering wikipedia questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = model.config.max_position_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_mask = inputs[\"token_type_ids\"] == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_tensor = tf.boolean_mask(inputs[\"input_ids\"], question_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(9,), dtype=int32, numpy=array([ 101, 2043, 2106, 2088, 2162, 1016, 2707, 1029,  102], dtype=int32)>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = max_length - len(question_tensor) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunked_input = OrderedDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chunks(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in inputs.items():\n",
    "    question = tf.boolean_mask(v, question_mask)\n",
    "    context =  tf.boolean_mask(v, ~question_mask)\n",
    "    chunks = list(get_chunks(context, chunk_size))\n",
    "    \n",
    "    for i, chunk in enumerate(chunks):\n",
    "        if i not in chunked_input:\n",
    "            chunked_input[i] = {}\n",
    "            \n",
    "        entire_input = tf.concat([question, chunk], axis=0)\n",
    "        \n",
    "        if i != len(chunks) - 1:\n",
    "            if k == 'input_ids':\n",
    "                entire_input = tf.concat([entire_input, tf.constant([102])], axis=0)\n",
    "            else:\n",
    "                entire_input = tf.concat([entire_input, tf.constant([1])], axis=0)\n",
    "        \n",
    "        chunked_input[i][k] = tf.reshape(entire_input, [1, entire_input.shape[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': <tf.Tensor: shape=(1, 512), dtype=int32, numpy=\n",
       " array([[  101,  2043,  2106,  2088,  2162,  1016,  2707,  1029,   102,\n",
       "          2088,  2162,  1045,  1006,  2411, 12066,  2004,  1059,  9148,\n",
       "          2030,  1059,  2860,  2487,  1007,  1010,  2036,  2124,  2004,\n",
       "          1996,  2034,  2088,  2162,  2030,  1996,  2307,  2162,  1010,\n",
       "          2001,  1037,  3795,  2162,  2008,  6354,  2013,  2654,  2251,\n",
       "          4554,  2000,  2340,  2281,  4271,  1012,  9530, 18532, 17822,\n",
       "         17191,  2135,  2649,  2004,  1000,  1996,  2162,  2000,  2203,\n",
       "          2035,  5233,  1000,  1010,  2009,  2419,  2000,  1996, 11240,\n",
       "         24411,  3370,  1997,  2062,  2084,  3963,  2454,  2510,  5073,\n",
       "          1010,  2164,  3438,  2454, 13481,  1010,  2437,  2009,  2028,\n",
       "          1997,  1996,  2922,  5233,  1999,  2381,  1012,  2009,  2003,\n",
       "          2036,  2028,  1997,  1996,  2757, 21292,  9755,  1999,  2381,\n",
       "          1010,  2007,  2019,  4358,  3157,  2454,  4337,  4630,  6677,\n",
       "          1998,  2410,  2454,  6831,  6677,  2004,  1037,  3622,  2765,\n",
       "          1997,  1996,  2162,  1010,  2096,  4525, 14052,  2015,  1998,\n",
       "          1996,  3141,  4271, 24442,  6090,  3207,  7712,  3303,  2178,\n",
       "          2459,  1516,  2531,  2454,  6677,  4969,  1012,  2006,  2654,\n",
       "          2238,  4554,  1010, 11721, 19716, 22360, 26927, 12273, 11514,\n",
       "          1010,  1037, 16163, 20180, 12292,  8986,  1010, 16370,  1996,\n",
       "         16951,  1011,  5588,  8215, 27463,  8965,  9684,  1999, 18354,\n",
       "          1010,  2877,  2000,  1996,  2251,  5325,  1012,  1999,  3433,\n",
       "          1010,  5118,  1011,  5872,  3843,  2019, 29227,  2000,  7238,\n",
       "          2006,  2603,  2251,  1012,  7238,  1005,  1055,  7514,  3478,\n",
       "          2000, 13225,  1996, 28439,  1010,  1998,  1996,  2048,  2333,\n",
       "          2000,  1037,  2162, 22849,  1012,  1037,  2897,  1997,  6970,\n",
       "          7878,  2075, 21277, 11792,  1996,  5325,  2013,  1037, 17758,\n",
       "          3277,  1999,  1996, 19733,  2000,  2028,  5994,  2087,  1997,\n",
       "          2885,  1012,  2011,  2251,  4554,  1010,  1996,  2307,  4204,\n",
       "          1997,  2885,  2020,  4055,  2046,  2048,  6056,  2015,  1024,\n",
       "          1996,  6420,  4372,  6528,  2618,  1010,  5398,  1997,  2605,\n",
       "          1010,  3607,  1010,  1998,  3725,  1025,  1998,  1996,  6420,\n",
       "          4707,  1997,  2762,  1010,  5118,  1011,  5872,  1010,  1998,\n",
       "          3304,  1012,  1996,  6420,  4707,  2001,  2069,  5600,  1999,\n",
       "          3267,  1010,  4352,  3304,  2000,  2994,  2041,  1997,  1996,\n",
       "          2162,  2127,  2258,  4936,  1010,  2043,  2009,  2587,  1996,\n",
       "          6035,  4204,  2044,  2049,  4262,  2007,  5118,  1011,  5872,\n",
       "         20111,  1012,  3607,  2371,  2009,  4072,  2000,  2067,  7238,\n",
       "          1010,  1998,  4844,  7704, 11240, 24411,  3370,  2044,  5118,\n",
       "          1011,  5872,  5806,  2098,  1996,  6514,  3007,  1997, 10291,\n",
       "          2006,  2654,  2251,  1012,  2440,  2845, 11240, 24411,  3370,\n",
       "          2001,  2623,  2006,  1996,  3944,  1997,  2382,  2251,  1025,\n",
       "          1996,  2206,  2154,  1010,  5118,  1011,  5872,  1998,  2762,\n",
       "          2106,  1996,  2168,  1010,  2096,  2762,  6303,  3607,  9703,\n",
       "         27965,  2063,  2306,  4376,  2847,  1012,  2043,  3607,  3478,\n",
       "          2000, 14037,  1010,  2762,  4161,  2162,  2006,  3607,  2006,\n",
       "          1015,  2257,  1999,  2490,  1997,  5118,  1011,  5872,  1010,\n",
       "          1996,  3732,  2206,  4848,  2006,  1020,  2257,  1025,  2605,\n",
       "          3641,  2440, 11240, 24411,  3370,  1999,  2490,  1997,  3607,\n",
       "          2006,  1016,  2257,  1012,  2762,  1005,  1055,  5656,  2005,\n",
       "          1037,  2162,  2006,  2048, 21430,  2114,  2605,  1998,  3607,\n",
       "          2001,  2000,  5901, 10152,  1996,  9625,  1997,  2049,  2390,\n",
       "          1999,  1996,  2225,  2000,  4154,  2605,  2306,  2416,  3134,\n",
       "          1010,  2059,  5670,  2749,  2000,  1996,  2264,  2077,  3607,\n",
       "          2071,  3929, 11240, 24411,  2063,  1025,  2023,  2001,  2101,\n",
       "          2124,  2004,  1996,  8040, 27766, 12879, 18940,  2933,  1012,\n",
       "          2006,  1016,  2257,  1010,  2762,  6303,  2489,  6019,  2083,\n",
       "          5706,  1010,  2019,  6827,  5783,  1999, 10910,   102]],\n",
       "       dtype=int32)>,\n",
       " 'token_type_ids': <tf.Tensor: shape=(1, 512), dtype=int32, numpy=\n",
       " array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1]], dtype=int32)>,\n",
       " 'attention_mask': <tf.Tensor: shape=(1, 512), dtype=int32, numpy=\n",
       " array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1]], dtype=int32)>}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunked_input[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = ''\n",
    "\n",
    "for k, chunk in chunked_input.items():\n",
    "    start_scores, end_scores = model(chunk)\n",
    "\n",
    "    answer_start = tf.argmax(start_scores, axis=1).numpy()[0]\n",
    "    answer_end = (tf.argmax(end_scores, axis=1) + 1).numpy()[0]\n",
    "    answ = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(chunk['input_ids'][0][answer_start:answer_end]))\n",
    "    \n",
    "    if answ != '[CLS]':\n",
    "        answer += answ + \" / \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1939 / 21 march 1918 / '"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
